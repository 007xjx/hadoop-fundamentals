{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with Spark MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from os import path as filepath\n",
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HDFS = \"hdfs://{}\".format(os.environ[\"HDFS\"])\n",
    "USER = filepath.join(HDFS, \"user\", \"ec2-user\")\n",
    "RATINGS = filepath.join(USER, \"dating/ratings.dat\")\n",
    "GENDER = filepath.join(USER, \"dating/gender.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_rating(line, sep=','):\n",
    "    \"\"\"\n",
    "    Parses a rating line\n",
    "    Returns: tuple of (random integer, (user_id, profile_id, rating))\n",
    "    \"\"\"\n",
    "    fields = line.strip().split(sep)\n",
    "    user_id = int(fields[0])     # convert user_id to int\n",
    "    profile_id = int(fields[1])  # convert profile_id to int\n",
    "    rating = float(fields[2])    # convert rated_id to int\n",
    "    return random.randint(1, 10), (user_id, profile_id, rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings = sc.textFile(RATINGS).map(parse_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_user(line, sep=','):\n",
    "    \"\"\"\n",
    "    Parses a user line\n",
    "    Returns: tuple of (user_id, gender)\n",
    "    \"\"\"\n",
    "    fields = line.strip().split(sep)\n",
    "    user_id = int(fields[0])  # convert user_id to int\n",
    "    gender = fields[1]\n",
    "    return user_id, gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = dict(sc.textFile(GENDER).map(parse_user).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 868466 and validation: 217058\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the training (80%) and validation (20%) set, based on last digit of timestamp\n",
    "num_partitions = 4\n",
    "\n",
    "training = ratings.filter(lambda x: x[0] > 2) \\\n",
    "                .values() \\\n",
    "                .repartition(num_partitions) \\\n",
    "                .cache()\n",
    "\n",
    "validation = ratings.filter(lambda x: x[0] <= 2) \\\n",
    "                .values() \\\n",
    "                .repartition(num_partitions) \\\n",
    "                .cache()\n",
    "\n",
    "num_training = training.count()\n",
    "num_validation = validation.count()\n",
    "\n",
    "print \"Training: %d and validation: %d\\n\" % (num_training, num_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rank is the number of latent factors in the model\n",
    "# num_iterations is the number of iterations to run.\n",
    "# reg_lambda specifies the regularization parameter in ALS\n",
    "\n",
    "rank = 8\n",
    "num_iterations = 8\n",
    "reg_lambda = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model was trained with rank = 8, lambda = 0.1, and 8 iterations. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "\n",
    "# Train model with training data and configured rank and iterations\n",
    "model = ALS.train(training, rank, num_iterations, reg_lambda)\n",
    "\n",
    "# evaluate the trained model on the validation set\n",
    "print \"The model was trained with rank = %d, lambda = %.1f, and %d iterations. \\n\" %(rank, reg_lambda, num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from operator import add\n",
    "\n",
    "def compute_rmse(model, data, n):\n",
    "    \"\"\"\n",
    "    Compute Root Mean Squared Error (RMSE), or square root of the average value\n",
    "        of (actual rating - predicted rating)^2\n",
    "    \"\"\"\n",
    "    predictions = model.predictAll(data.map(lambda x: (x[0], x[1])))\n",
    "    \n",
    "    predictions_ratings = predictions.map(lambda x: ((x[0], x[1]), x[2])) \\\n",
    "                        .join(data.map(lambda x: ((x[0], x[1]), x[2]))) \\\n",
    "                        .values()\n",
    "    \n",
    "    return sqrt(predictions_ratings.map(lambda x: (x[0] - x[1]) ** 2).reduce(add) / float(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model was trained with rank=8, lambda=0.1, and 8 iterations.\n",
      "Its RMSE on the validation set is 1.757121.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print RMSE of model\n",
    "validation_rmse = compute_rmse(model, validation, num_validation)\n",
    "\n",
    "print \"The model was trained with rank=%d, lambda=%.1f, and %d iterations.\" %(rank, reg_lambda, num_iterations)\n",
    "print \"Its RMSE on the validation set is %f.\\n\" % validation_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligible partners recommended for User ID: 5\n",
      " 1: 179536\n",
      " 2: 54497\n",
      " 3: 39842\n",
      " 4: 72128\n",
      " 5: 52412\n",
      " 6: 32754\n",
      " 7: 24360\n",
      " 8: 82600\n",
      " 9: 14862\n",
      "10: 99659\n"
     ]
    }
   ],
   "source": [
    "matchseeker = 5\n",
    "gender_filter = 'F'\n",
    "\n",
    "# Filter on preferred gender\n",
    "partners = sc.parallelize([u[0] for u in filter(lambda u: u[1] == gender_filter, users.items())])\n",
    "\n",
    "# run predictions with trained model\n",
    "predictions = model.predictAll(partners.map(lambda x: (matchseeker, x))).collect()\n",
    "\n",
    "# sort the recommendations\n",
    "recommendations = sorted(predictions, key=lambda x: x[2], reverse=True)[:10]\n",
    "\n",
    "print \"Eligible partners recommended for User ID: %d\" % matchseeker\n",
    "for i in xrange(len(recommendations)):\n",
    "    print (\"%2d: %s\" % (i + 1, recommendations[i][1])).encode('ascii', 'ignore')\n",
    "\n",
    "# clean up\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
