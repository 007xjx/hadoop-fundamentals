{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "from operator import add \n",
    "from operator import itemgetter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Directories \n",
    "DATA = os.path.abspath(os.path.join(\"..\", \"data\"))\n",
    "TEXT = os.path.join(DATA, \"spam_classifier\")\n",
    "\n",
    "# Classes \n",
    "SPAM = 0 \n",
    "HAM  = 1 \n",
    "\n",
    "# Labels \n",
    "LABELS = {\n",
    "    SPAM: \"spam\",\n",
    "    HAM: \"ham\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Extracting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create RDDs for both Spam and Ham \n",
    "spam = sc.textFile(os.path.join(TEXT, \"spam.txt\"))\n",
    "ham  = sc.textFile(os.path.join(TEXT, \"ham.txt\"))\n",
    "\n",
    "# Map the labels to each. \n",
    "spam = spam.map(lambda line: (SPAM, line))\n",
    "ham  = ham.map(lambda line: (HAM, line))\n",
    "\n",
    "# Append the datasets with their labels \n",
    "text = spam.union(ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the DataFrame RDD \n",
    "text = text.toDF([\"label\", \"line\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"line\", outputCol=\"words\")\n",
    "words = tokenizer.transform(text)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=200)\n",
    "features = hashingTF.transform(words)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(features)\n",
    "rescaled = idfModel.transform(features)\n",
    "\n",
    "rescaled.select(\"label\", \"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Bayesian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the model family \n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a data frame of only label and features\n",
    "data = rescaled.select(\"label\", \"features\")\n",
    "\n",
    "# Create train and test splits. \n",
    "splits = data.randomSplit([0.8, 0.2], 42)\n",
    "train  = splits[0]\n",
    "test   = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instantiate the model form and set its hyperparameters\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "\n",
    "# Train the model\n",
    "model = nb.fit(train)\n",
    "\n",
    "# Make predictions on the test data. \n",
    "predictions = model.transform(test)\n",
    "predictions.show()\n",
    "\n",
    "# Compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = {:0.3f}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
